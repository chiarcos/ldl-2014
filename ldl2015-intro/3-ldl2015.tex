\section{LDL-2015: The 4th Workshop on Linked Data in Linguistics}

For the 4th edition of the workshop on Linked Data in Linguistics, we invited contributions discussing the application of the Linked Open Data paradigm to linguistic data in various fields of linguistics, natural language processing, knowledge management and information technology in order to present and discuss \emph{principles}, \emph{case studies}, and \emph{best practices} for representing, publishing and linking mono- and multilingual linguistic and knowledge data collections, including corpora, grammars, dictionaries, wordnets, translation memories, domain specific ontologies etc. 

In this regard, the Linked Data paradigm provides an important step towards making linguistic data: 
i) easily and uniformly queryable, 
ii) interoperable and 
iii) sharable over the Web using open standards such as the HTTP protocol and the RDF data model. 
As a result of preceding LDL workshops and the activities of the communities involved, a considerable amount of linguistic linked open data resources has been established, so that our community is now increasingly aiming to shift the focus from resource creation to resource linking and further to the development of innovative applications of these resources in linguistics and NLP. For the current issue of LDL, we thus focus on \emph{resouces and applications}.

Accordingly, LDL-2015 provides a forum for researchers on natural language processing and semantic web technologies to present case studies and best practices on the exploitation of linguistic resources exposed on the Web for \textbf{Natural Language Processing} applications, or other content-centered applications such as content analytics, knowledge extraction, etc. The availability of massive linked open knowledge resources raises the question how such data can be suitably employed to facilitate different NLP tasks and research questions. Following the tradition of earlier LDL workshops, we encouraged contributions to the Linguistic Linked Open Data (LLOD) cloud and research on this basis. In particular, this pertains to contributions that demonstrate an added value resulting from the combination of linked datasets and ontologies as a source for semantic information with linguistic resources published according to as linked data principles. Another important question to be addressed in the workshop is how Natural Language Processing techniques can be employed to further facilitate the growth and enrichment of linguistic resources on the Web.

The call for papers emphasized the following topics:

\begin{description}
\item[Resources] \hspace{0.5cm}\\
	\begin{itemize}
	\item Modelling linguistic data and metadata with OWL and/or RDF.
    \item Ontologies for linguistic data and metadata collections as well as cross-lingual retrieval.
    \item Descriptions of data sets following Linked Data principles.
    \item Legal and social aspects of Linguistic Linked Open Data.
    \item Best practices for the publication and linking of multilingual knowledge resources.
	\end{itemize}
\item[Applications] \hspace{0.5cm}\\
	\begin{itemize}
	\item Applications of such data, other ontologies or linked data from any subdiscipline of linguistics or NLP.
    \item The role of (Linguistic) Linked Open Data to address challenges of multilinguality and interoperability.
    \item Application and applicability of (Linguistic) Linked Open Data for knowledge extraction, machine translation and other NLP tasks.
    \item NLP contributions to (Linguistic) Linked Open Data.
	\end{itemize}
\end{description}

\noindent 
For these topics, we received 14 submissions which were reviewed by at least 3 members of the program committee. 
On this basis, we accepted 6 submissions as full papers and 3 as short papers.

The 9 accepted papers address a wide range of problems in the area of NLP and (Linguistic) Linked Open Data, pertaining to modeling resources and resource metadata, NLP applications of/for LLOD and aspects of resource evaluation and curation. In addition, the workshop will feature an invited talk by Key-Sun Choi, KAIST, Korea.

\subsection{Modelling Resources}

Traditionally, resource modeling has been a focus area of LDL workshops, especially with respect to lexical-conceptual resources. 
Nevertheless, a number of open research questions remains, including possible extensions of existing vocabularies, as well as the extension to novel types of linguistic resources.

% (Submission #12), short
Certainly, WordNet is \emph{the} classical lexical-conceptual resource in the context of LLOD, and different WordNet editions have been provided as Linked Data using the \emph{lemon} vocabulary, already.
Yet, as Lee and Hsieh point out in their short paper on `Linguistic Linked Data in Chinese: The Case of Chinese Wordnet', the model does not allow for finer-grained distinction of a word sense, or meaning facets, used in the Chinese Wordnet. Along with these observations, which may motivate an extension of the \emph{lemon} model in the longer perspective, they describe the current status of the LLOD edition of the Chinese WordNet in relation to \emph{lemon} and the ontology proposed by the Global WordNet Association to show how the Chinese Wordnet as Linked Data can be integrated into the LLOD edition of the Global WordNet Grid.

% (Submission #3), long
A different kind of resource is presented by Krause at al. and  their paper on `Sar-graphs: A Linked Linguistic Knowledge Resource Connecting Facts with Language'. Sar-graphs extends relations from existing lexical-conceptual resources (BabelNet, WordNet, UBY and FrameNet) with the linguistic patterns a language can use to express instances of these relations. In addition, they describe a language-independent method to automatically construct novel sar-graph instances. 

\subsection{Modeling Resource Metadata}

Language resources are a cornerstone of linguistic research and for the development of natural language processing tools, but the discovery of relevant resources remains a challenging task. 
This is due to the fact that relevant metadata records are spread among different repositories and it is currently impossible to query all these repositories in an integrated fashion, as they use different data models and vocabularies. The contributions in this group address the problem of harmonizing linguistic resource metadata, both general, and specifically for licensing information.

% Submission #9, long
At present, the existence of multiple metadata repositories, and the insufficient degree of interoperability between them limits the usability of metadata repositories for the LLOD world. 
In `Reconciling Heterogeneous Descriptions of Language Resources', McCrae et al. present an attempt to collect and harmonize the metadata of different repositories, making them queriable and browsable in an integrated way on the basis of RDF and linked data technologies. Further, they present an approach to automatically harmonize resources by mapping values of attributes -- such as the type, license or intended use of a resource -- into normalized values, as well as to automatically detect duplicates.

% (Submission #11), long
The specific problem of legal metadata, i.e., licensing information, is addressed in `RDF Representation of Licenses for Language Resources'. 
Here, Rodriguez-Doncel and Labropoulou address the issue of license declaration for linguistic linked open data and introduce the Open Digital Rights Language (ODRL) core model in applications and examples.

\subsection{Applications and Algorithms}

Contributions on applications and algorithms comprise contributions addressing potential and actual use cases of Linked Linguistic Linked Open Data as well as automated procedures to extend existing LLOD resources.

% Submission #8, data set
The actual value of linked data is in the linking as it supports integration and discovery of data, but the manual creation of links between datasets is costly and therefore does not scale well. Therefore, automatic linking approaches are of great importance to increase the quality and degree of linking of the Linguistic Linked Data cloud.
In this context, Siemoneit, McCrae and Cimiano describe with their short paper on `Linking Four Heterogeneous Language Resources as Linked Data' methodology and results of an experiment in the mutual automatic linking of the \emph{European Migration Network (EMN)} glossary, the \emph{Interactive Terminology for Europe} (IATE), BabelNet, and the Manually Annotated Subcorpus (MASC) of the American National Corpus.

A different potential field of application is addressed by McGovern, O'Connor and Wade in their paper on `From DBpedia and WordNet hierarchies to LinkedIn and Twitter', where they study using WordNet and DBpedia information to compare users' descriptions of their knowledge and background on two social media platforms.

% (Submission #14), long
Finally, S\'{a}nchez-Rada, Iglesias and Gil address preliminaries of the application of `A Linked Data Model for Multimodal Sentiment and Emotion Analysis'.
As in other fields of NLP, the lack of standard formats in sentiment analysis hinders interoperability, a deficit previously address by using the NLP Interchange Format NIF as both a common semantic format and an API for textual sentiment analysis. However, the focus on textual sentiment analysis limits the applicability of this approach to multimodal content, for which the authors propose multimedia extension of NIF that can be leveraged for multimodal applications. 

\subsection{Evaluation and Curation}

The papers in this group address issues of curation and evaluation for/using LLOD.

% (Submission #5), long 
In their paper on `Seeing is Correcting: curating lexical resources using social interfaces', Real et al. describe curation efforts on OpenWordnet-PT, an automatically created Portuguese WordNet and an RDF/OWL-native resource. 
The authors introduce a web interface designed for efficient manual curation of this data, a user interfaces that allows ordinary users and (not only computational) linguists to help checking and cleaning up of the quality of the resource in a collaborative fashion. They emphasize the importance of linked data in this process, in particular the ability to keep track of provenance information during the whole life-cycle of the RDF resource.

% Submission #7, data set
A different aspect of evaluation, namely the creation and use of LLOD resources for evaluating NLP applications, is addressed by Santus et al. in their short paper on `EVALution 1.0: an Evolving Semantic Dataset for Training and Evaluation of Distributional Semantic Models'. 
The authors introduce EVALution 1.0, a dataset designed for the training and the evaluation of Distributional Semantic Models consisting of almost 7.5K tuples which instantiate several semantic relations between word pairs (including hypernymy, synonymy, antonymy, meronymy) as well as additional information (i.e. relation domain, word frequency, word POS, word semantic field, etc.) that can be used for either filtering the pairs or performing an in-depth analysis of the results. 

\subsection{Invited Talk by Key-Sun Choi}

In addition to full and short papers/dataset descriptions, LDL-2015 will feature Key-Sun Choi as an invited speaker. Key-Sun Choi is professor of the Korea Advanced Institute of Science and Technology (KAIST), Korea, since 1988, where he had been Head of Computer Science Department (2006-2011) and recently founded the KAIST research group on Open Knowledge Convergence (since 2012). Key-Sun Choi has contributed to Department of Knowledge Service Engineering and Graduate School of Information Security in KAIST as a Joint Professor.

He founded and directed Korterm (Korea Terminology Research Center for Natural Language and Knowledge Engineering, 1998) and Bora (National Research Resource Bank for Language and Annotation, 2003). He had been an invited researcher in NEC C\&C Lab of Japan (1987-1988), a visiting scholar of CSLI of Stanford University (1997), and an invited researcher of NHK Science \& Technology Research Laboratories (2002). His areas of expertise are natural language processing, ontology and knowledge engineering, semantic web and linked data, and their infrastructure including text analytics. He served as President (2009-2010) of AFNLP (Asia Federation of Natural Language Processing), the President (2006) of Korean Cognitive Science Society, and the Secretary of ISO/TC37/SC4 for language resource management standards since 2002. 

Recent key areas of his work are entity linking and predicate linking from text to DBpedia-like knowledge-bases and the enrichment of text, mainly for Korean. 
% But when we use Korean DBpedia, a few properties in RDF are linked to ontology...  % ???
In his talk, he will focus on this line of research and address aspects of lexicalizing ontologies, mapping local properties to ontologies, extracting base ontologies and enhancing multilingualism in DBpedia.

As organizers of LDL-2015, we are happy to welcome Key-Sun Choi as key note speaker to the workshop and look forward for fruitful discussions on the interface of Semantic Web and NLP in Beijing.

